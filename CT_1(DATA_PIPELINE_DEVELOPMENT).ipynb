{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Function to load data\n",
        "def load_data(file_path):\n",
        "\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, target_column):\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Define categorical and numerical columns\n",
        "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "    # Preprocessing for numerical data\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Preprocess categorical data\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessors in a column transformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return preprocessor, X, y\n",
        "\n",
        "# Function to create a pipeline\n",
        "def create_pipeline(preprocessor):\n",
        "    \"\"\"Create a pipeline for the ETL process.\"\"\"\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor)\n",
        "    ])\n",
        "    return pipeline\n",
        "\n",
        "# Function to save transformed data\n",
        "def save_transformed_data(transformed_data, output_path):\n",
        "    \"\"\"Save the transformed data to a CSV file.\"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    transformed_data.to_csv(output_path, index=False)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # File paths\n",
        "    input_file_path = '/content/California_data.csv'\n",
        "    output_file_path = '/content/transformed_data.csv'\n",
        "    # Load the data\n",
        "    data = load_data(input_file_path)\n",
        "\n",
        "    # Preprocess the data\n",
        "    target_column = 'AveOccup'  # Replace with your target column\n",
        "    preprocessor, X, y = preprocess_data(data, target_column)\n",
        "\n",
        "    # Create pipeline\n",
        "    pipeline = create_pipeline(preprocessor)\n",
        "\n",
        "    # Fit and transform the data\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "\n",
        "    # Convert transformed data back to DataFrame\n",
        "    feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "    X_transformed_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
        "\n",
        "    # Save the transformed data\n",
        "    save_transformed_data(X_transformed_df, output_file_path)\n",
        "    print(f\"Transformed data saved to {output_file_path}\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "94BLPRFtA_wA",
        "outputId": "467125c3-c4ca-43b9-9953-f5f5e15bf4d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data saved to /content/transformed_data.csv\n"
          ]
        }
      ]
    }
  ]
}