{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "ObPoIJSIIA9A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data\n",
        "def load_data(file_path):\n",
        "\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "print(load_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIyngaq5IIdr",
        "outputId": "6d20653e-93ae-4922-f06d-b2a9f456b1c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function load_data at 0x7b72f3d95ee0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess data\n",
        "def preprocess_data(data, target_column):\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Define categorical and numerical columns\n",
        "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "    # Preprocessing for numerical data\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Preprocess categorical data\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine preprocessors in a column transformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return preprocessor, X, y\n",
        "\n",
        "target_column = 'target'\n",
        "\n",
        "# Preprocess the data\n",
        "preprocessor, X, y = preprocess_data(data, target_column)\n",
        "\n",
        "# Print the results\n",
        "print(\"Features (X):\")\n",
        "print(X)\n",
        "\n",
        "print(\"\\nTarget (y):\")\n",
        "print(y)\n",
        "\n",
        "print(\"\\nPreprocessor:\")\n",
        "print(preprocessor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG4ftIo8IIg5",
        "outputId": "d8f75657-1657-472a-b896-019efd55e6a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X):\n",
            "    age  gender  income\n",
            "0  25.0    Male   50000\n",
            "1  30.0  Female   60000\n",
            "2  22.0    Male   45000\n",
            "3  35.0  Female   70000\n",
            "4   NaN  Female   80000\n",
            "\n",
            "Target (y):\n",
            "0    0\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "Name: target, dtype: int64\n",
            "\n",
            "Preprocessor:\n",
            "ColumnTransformer(transformers=[('num',\n",
            "                                 Pipeline(steps=[('imputer', SimpleImputer()),\n",
            "                                                 ('scaler', StandardScaler())]),\n",
            "                                 Index(['age', 'income'], dtype='object')),\n",
            "                                ('cat',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(strategy='most_frequent')),\n",
            "                                                 ('onehot',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
            "                                 Index(['gender'], dtype='object'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a pipeline\n",
        "def create_pipeline(preprocessor):\n",
        "    \"\"\"Create a pipeline for the ETL process.\"\"\"\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor)\n",
        "    ])\n",
        "    return pipeline\n",
        "\n",
        "# Function to save transformed data\n",
        "def save_transformed_data(transformed_data, output_path):\n",
        "    \"\"\"Save the transformed data to a CSV file.\"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    transformed_data.to_csv(output_path, index=False)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # File paths\n",
        "    input_file_path = '/content/California_data.csv'\n",
        "    output_file_path = '/content/transformed_data.csv'\n",
        "    # Load the data\n",
        "    data = load_data(input_file_path)\n",
        "\n",
        "    # Preprocess the data\n",
        "    target_column = 'AveOccup'  # Replace with your target column\n",
        "    preprocessor, X, y = preprocess_data(data, target_column)\n",
        "\n",
        "    # Create pipeline\n",
        "    pipeline = create_pipeline(preprocessor)\n",
        "\n",
        "    # Fit and transform the data\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "\n",
        "    # Convert transformed data back to DataFrame\n",
        "    feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "    X_transformed_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
        "\n",
        "    # Save the transformed data\n",
        "    save_transformed_data(X_transformed_df, output_file_path)\n",
        "    print(f\"Transformed data saved to {output_file_path}\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LnKyP9eIIkj",
        "outputId": "33dff87b-42de-41ca-bf12-cd8e3d9231e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data saved to /content/transformed_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to create a pipeline\n",
        "def create_pipeline(preprocessor):\n",
        "    \"\"\"Create a pipeline for the ETL process.\"\"\"\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor)\n",
        "    ])\n",
        "    return pipeline\n",
        "\n",
        "# Function to save transformed data\n",
        "def save_transformed_data(transformed_data, output_path):\n",
        "    \"\"\"Save the transformed data to a CSV file.\"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    transformed_data.to_csv(output_path, index=False)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # File paths\n",
        "    input_file_path = '/content/California_data.csv'  # Replace with your actual file path\n",
        "    output_file_path = '/content/transformed_data.csv'  # Output file path\n",
        "\n",
        "    # Load the data\n",
        "    data = load_data(input_file_path)\n",
        "    print(\"Loaded Data:\")\n",
        "    print(data.head())  # Print the first few rows of the loaded data\n",
        "\n",
        "    # Preprocess the data\n",
        "    target_column = 'AveOccup'  # Replace with your target column\n",
        "    preprocessor, X, y = preprocess_data(data, target_column)\n",
        "\n",
        "    print(\"\\nFeatures (X) before transformation:\")\n",
        "    print(X.head())  # Print the first few rows of the features\n",
        "\n",
        "    # Create pipeline\n",
        "    pipeline = create_pipeline(preprocessor)\n",
        "\n",
        "    # Fit and transform the data\n",
        "    X_transformed = pipeline.fit_transform(X)\n",
        "\n",
        "    # Convert transformed data back to DataFrame\n",
        "    feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "    X_transformed_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
        "\n",
        "    print(\"\\nTransformed Features:\")\n",
        "    print(X_transformed_df.head())  # Print the first few rows of the transformed features\n",
        "\n",
        "    # Save the transformed data\n",
        "    save_transformed_data(X_transformed_df, output_file_path)\n",
        "    print(f\"\\nTransformed data saved to {output_file_path}\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x1Yia2JIIn-",
        "outputId": "aafbe7c0-821a-4849-eba5-123a8cf9dfe8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Data:\n",
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
            "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
            "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
            "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
            "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
            "\n",
            "   Longitude  MedHouseVal  \n",
            "0    -122.23        4.526  \n",
            "1    -122.22        3.585  \n",
            "2    -122.24        3.521  \n",
            "3    -122.25        3.413  \n",
            "4    -122.25        3.422  \n",
            "\n",
            "Features (X) before transformation:\n",
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  Latitude  Longitude  \\\n",
            "0  8.3252      41.0  6.984127   1.023810       322.0     37.88    -122.23   \n",
            "1  8.3014      21.0  6.238137   0.971880      2401.0     37.86    -122.22   \n",
            "2  7.2574      52.0  8.288136   1.073446       496.0     37.85    -122.24   \n",
            "3  5.6431      52.0  5.817352   1.073059       558.0     37.85    -122.25   \n",
            "4  3.8462      52.0  6.281853   1.081081       565.0     37.85    -122.25   \n",
            "\n",
            "   MedHouseVal  \n",
            "0        4.526  \n",
            "1        3.585  \n",
            "2        3.521  \n",
            "3        3.413  \n",
            "4        3.422  \n",
            "\n",
            "Transformed Features:\n",
            "   num__MedInc  num__HouseAge  num__AveRooms  num__AveBedrms  num__Population  \\\n",
            "0     2.344766       0.982143       0.628559       -0.153758        -0.974429   \n",
            "1     2.332238      -0.607019       0.327041       -0.263336         0.861439   \n",
            "2     1.782699       1.856182       1.155620       -0.049016        -0.820777   \n",
            "3     0.932968       1.856182       0.156966       -0.049833        -0.766028   \n",
            "4    -0.012881       1.856182       0.344711       -0.032906        -0.759847   \n",
            "\n",
            "   num__Latitude  num__Longitude  num__MedHouseVal  \n",
            "0       1.052548       -1.327835          2.129631  \n",
            "1       1.043185       -1.322844          1.314156  \n",
            "2       1.038503       -1.332827          1.258693  \n",
            "3       1.038503       -1.337818          1.165100  \n",
            "4       1.038503       -1.337818          1.172900  \n",
            "\n",
            "Transformed data saved to /content/transformed_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52i38yIvIIx6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}